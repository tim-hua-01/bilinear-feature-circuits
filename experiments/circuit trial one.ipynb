{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following commands for vast ai:\n",
    "\n",
    "conda install gh --channel conda-forge\n",
    "gh auth login\n",
    "gh repo clone bilinear-feature-circuits\n",
    "cd bilinear-feature-circuits\n",
    "git submodule --update\n",
    "wget https://huggingface.co/saprmarks/pythia-70m-deduped-saes/resolve/main/dictionaries_pythia-70m-deduped_10.zip\n",
    "#unzip dictionaries_pythia-70m-deduped_10.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 760
    },
    "id": "OJ16XnQyGVsz",
    "outputId": "08d3d36e-af25-48f8-fe95-d718b90d23df",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
      "  Cloning https://github.com/callummcdougall/CircuitsVis.git to /tmp/pip-req-build-vnq9clqi\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/callummcdougall/CircuitsVis.git /tmp/pip-req-build-vnq9clqi\n",
      "  Resolved https://github.com/callummcdougall/CircuitsVis.git to commit 1e6129d08cae7af9242d9ab5d3ed322dd44b4dd3\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting importlib-metadata<6.0.0,>=5.1.0 (from circuitsvis==0.0.0)\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting numpy<2.0,>=1.23 (from circuitsvis==0.0.0)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: torch<3.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from circuitsvis==0.0.0) (2.5.1+cu124)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis==0.0.0) (3.20.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch<3.0,>=2.0->circuitsvis==0.0.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<3.0,>=2.0->circuitsvis==0.0.0) (3.0.2)\n",
      "Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Building wheels for collected packages: circuitsvis\n",
      "  Building wheel for circuitsvis (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for circuitsvis: filename=circuitsvis-0.0.0-py3-none-any.whl size=6172338 sha256=68db3afdea2d0e0a3142f410b568f7fb47ad97e53e63d3bda9d115fcb49e76ac\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-np__a1a1/wheels/00/ce/19/651aed367fa8cefad943dece40a2248cef6588697047472ef1\n",
      "Successfully built circuitsvis\n",
      "Installing collected packages: numpy, importlib-metadata, circuitsvis\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed circuitsvis-0.0.0 importlib-metadata-5.2.0 numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkFShEAQF0th",
    "outputId": "78546ddd-05fd-4362-efcd-2129e609468b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Collecting torchtyping\n",
      "  Downloading torchtyping-0.1.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from torchtyping) (2.5.1+cu124)\n",
      "Collecting typeguard<3,>=2.11.1 (from torchtyping)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.7.0->torchtyping) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.7.0->torchtyping) (3.0.2)\n",
      "Downloading torchtyping-0.1.5-py3-none-any.whl (17 kB)\n",
      "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, torchtyping\n",
      "Successfully installed torchtyping-0.1.5 typeguard-2.13.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Collecting jaxtyping\n",
      "  Downloading jaxtyping-0.2.36-py3-none-any.whl.metadata (6.5 kB)\n",
      "Downloading jaxtyping-0.2.36-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: jaxtyping\n",
      "Successfully installed jaxtyping-0.2.36\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Collecting transformer_lens\n",
      "  Downloading transformer_lens-2.9.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (1.2.0)\n",
      "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
      "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
      "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (3.2.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (0.8.0)\n",
      "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
      "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (0.2.36)\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (2.2.3)\n",
      "Collecting rich>=12.6.0 (from transformer_lens)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.10 in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (2.5.1+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (4.66.5)\n",
      "Requirement already satisfied: transformers>=4.37.2 in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (4.47.0)\n",
      "Collecting typeguard<5.0,>=4.2 (from transformer_lens)\n",
      "  Downloading typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from transformer_lens) (4.12.2)\n",
      "Collecting wandb>=0.13.5 (from transformer_lens)\n",
      "  Downloading wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer_lens) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer_lens) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer_lens) (0.26.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer_lens) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (3.11.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.5->transformer_lens) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=12.6.0->transformer_lens)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10->transformer_lens) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10->transformer_lens) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.37.2->transformer_lens) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.37.2->transformer_lens) (0.21.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer_lens)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (5.29.1)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (2.10.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb>=0.13.5->transformer_lens)\n",
      "  Downloading sentry_sdk-2.19.2-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting setproctitle (from wandb>=0.13.5->transformer_lens)\n",
      "  Downloading setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (72.1.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.18.3)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10->transformer_lens) (3.0.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading transformer_lens-2.9.1-py3-none-any.whl (176 kB)\n",
      "Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
      "Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
      "Downloading wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading sentry_sdk-2.19.2-py2.py3-none-any.whl (322 kB)\n",
      "Downloading setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: better-abc, typeguard, smmap, setproctitle, sentry-sdk, mdurl, fancy-einsum, docker-pycreds, beartype, markdown-it-py, gitdb, rich, gitpython, wandb, transformer_lens\n",
      "  Attempting uninstall: typeguard\n",
      "    Found existing installation: typeguard 2.13.3\n",
      "    Uninstalling typeguard-2.13.3:\n",
      "      Successfully uninstalled typeguard-2.13.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtyping 0.1.5 requires typeguard<3,>=2.11.1, but you have typeguard 4.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 docker-pycreds-0.4.0 fancy-einsum-0.0.3 gitdb-4.0.11 gitpython-3.1.43 markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.9.4 sentry-sdk-2.19.2 setproctitle-1.3.4 smmap-5.0.1 transformer_lens-2.9.1 typeguard-4.4.1 wandb-0.19.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Collecting umap\n",
      "  Downloading umap-0.1.1.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: umap\n",
      "  Building wheel for umap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3542 sha256=786f97e0d5dbec74cd466cdd2679b30696065aee6842d2eb5a62a92a16ec7080\n",
      "  Stored in directory: /root/.cache/pip/wheels/82/d8/73/e9eb3334baaad795ff0278363ff1aca7568bdf2793e452a527\n",
      "Successfully built umap\n",
      "Installing collected packages: umap\n",
      "Successfully installed umap-0.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.11/site-packages (0.23.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets>=2.18.0\n",
    "!pip install einops>=0.7.0\n",
    "!pip install graphviz>=0.20.1\n",
    "!pip install nnsight>=0.2.9\n",
    "!pip install torchtyping\n",
    "!pip install jaxtyping\n",
    "!pip install transformer_lens\n",
    "!pip install umap\n",
    "!pip install zstandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rqhyDYVxUeWz"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ROVZw-cGJcOh"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath('..')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from dictionary_learning import AutoEncoder\n",
    "import circuit\n",
    "from circuit import get_circuit\n",
    "from circuit_plotting import plot_circuit\n",
    "from activation_utils import SparseAct\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "\n",
    "DEBUGGING = True\n",
    "if DEBUGGING:\n",
    "    tracer_kwargs = {'validate' : True, 'scan' : True}\n",
    "else:\n",
    "    tracer_kwargs = {'validate' : False, 'scan' : False}\n",
    "\n",
    "DEVICE = 'cuda:0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MI3aUIc9QYUC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map=DEVICE, dispatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zaHOwq_RJcOh"
   },
   "outputs": [],
   "source": [
    "# utilities for loading data\n",
    "dataset = load_dataset(\"LabHC/bias_in_bios\")\n",
    "profession_dict = {'professor' : 21, 'nurse' : 13}\n",
    "male_prof = 'professor'\n",
    "female_prof = 'nurse'\n",
    "\n",
    "batch_size = 1024\n",
    "SEED = 42\n",
    "\n",
    "def get_data(train=True, ambiguous=True, batch_size=128, seed=SEED):\n",
    "    if train:\n",
    "        data = dataset['train']\n",
    "    else:\n",
    "        data = dataset['test']\n",
    "    if ambiguous:\n",
    "        neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 0]\n",
    "        pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 1]\n",
    "        n = min([len(neg), len(pos)])\n",
    "        neg, pos = neg[:n], pos[:n]\n",
    "        data = neg + pos\n",
    "        labels = [0]*n + [1]*n\n",
    "        idxs = list(range(2*n))\n",
    "        random.Random(seed).shuffle(idxs)\n",
    "        data, labels = [data[i] for i in idxs], [labels[i] for i in idxs]\n",
    "        true_labels = spurious_labels = labels\n",
    "    else:\n",
    "        neg_neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 0]\n",
    "        neg_pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 1]\n",
    "        pos_neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 0]\n",
    "        pos_pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 1]\n",
    "        n = min([len(neg_neg), len(neg_pos), len(pos_neg), len(pos_pos)])\n",
    "        neg_neg, neg_pos, pos_neg, pos_pos = neg_neg[:n], neg_pos[:n], pos_neg[:n], pos_pos[:n]\n",
    "        data = neg_neg + neg_pos + pos_neg + pos_pos\n",
    "        true_labels     = [0]*n + [0]*n + [1]*n + [1]*n\n",
    "        spurious_labels = [0]*n + [1]*n + [0]*n + [1]*n\n",
    "        idxs = list(range(4*n))\n",
    "        random.Random(seed).shuffle(idxs)\n",
    "        data, true_labels, spurious_labels = [data[i] for i in idxs], [true_labels[i] for i in idxs], [spurious_labels[i] for i in idxs]\n",
    "\n",
    "    batches = [\n",
    "        (data[i:i+batch_size], t.tensor(true_labels[i:i+batch_size], device=DEVICE), t.tensor(spurious_labels[i:i+batch_size], device=DEVICE)) for i in range(0, len(data), batch_size)\n",
    "    ]\n",
    "\n",
    "    return batches\n",
    "\n",
    "def get_subgroups(train=True, ambiguous=True, batch_size=128, seed=SEED):\n",
    "    if train:\n",
    "        data = dataset['train']\n",
    "    else:\n",
    "        data = dataset['test']\n",
    "    if ambiguous:\n",
    "        neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 0]\n",
    "        pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 1]\n",
    "        neg_labels, pos_labels = (0, 0), (1, 1)\n",
    "        subgroups = [(neg, neg_labels), (pos, pos_labels)]\n",
    "    else:\n",
    "        neg_neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 0]\n",
    "        neg_pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 1]\n",
    "        pos_neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 0]\n",
    "        pos_pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 1]\n",
    "        neg_neg_labels, neg_pos_labels, pos_neg_labels, pos_pos_labels = (0, 0), (0, 1), (1, 0), (1, 1)\n",
    "        subgroups = [(neg_neg, neg_neg_labels), (neg_pos, neg_pos_labels), (pos_neg, pos_neg_labels), (pos_pos, pos_pos_labels)]\n",
    "\n",
    "    out = {}\n",
    "    for data, label_profile in subgroups:\n",
    "        out[label_profile] = []\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            text = data[i:i+batch_size]\n",
    "            out[label_profile].append(\n",
    "                (\n",
    "                    text,\n",
    "                    t.tensor([label_profile[0]]*len(text), device=DEVICE),\n",
    "                    t.tensor([label_profile[1]]*len(text), device=DEVICE)\n",
    "                )\n",
    "            )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B91RTKHRJcOi"
   },
   "outputs": [],
   "source": [
    "# probe training hyperparameters\n",
    "\n",
    "layer = 4 # the model layer to attach linear classification head to\n",
    "\n",
    "class Probe(nn.Module):\n",
    "    def __init__(self, activation_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(activation_dim, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.net(x).squeeze(-1)\n",
    "        return logits\n",
    "\n",
    "def train_probe(get_acts, label_idx=0, batches=get_data(), lr=1e-2, epochs=1, dim=512, seed=SEED):\n",
    "    t.manual_seed(seed)\n",
    "    probe = Probe(dim).to('cuda:0')\n",
    "    optimizer = t.optim.AdamW(probe.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for batch in tqdm(batches):\n",
    "            text = batch[0]\n",
    "            labels = batch[label_idx+1]\n",
    "            acts = get_acts(text)\n",
    "            logits = probe(acts)\n",
    "            loss = criterion(logits, labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return probe, losses\n",
    "\n",
    "def test_probe(probe, get_acts, label_idx=0, batches=get_data(train=False), seed=SEED):\n",
    "    with t.no_grad():\n",
    "        corrects = []\n",
    "\n",
    "        for batch in tqdm(batches):\n",
    "            text = batch[0]\n",
    "            labels = batch[label_idx+1]\n",
    "            acts = get_acts(text)\n",
    "            logits = probe(acts)\n",
    "            preds = (logits > 0.0).long()\n",
    "            corrects.append((preds == labels).float())\n",
    "        return t.cat(corrects).mean().item()\n",
    "\n",
    "def get_acts(text):\n",
    "    with t.no_grad():\n",
    "        with model.trace(text, **tracer_kwargs):\n",
    "            attn_mask = model.inputs[1]['attention_mask']\n",
    "            acts = model.gpt_neox.layers[layer].output[0]\n",
    "            acts = acts * attn_mask[:, :, None]\n",
    "            acts = acts.sum(1) / attn_mask.sum(1)[:, None]\n",
    "            acts = acts.save()\n",
    "        return acts.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mevUIDmeVK2r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EdX5APPeR_9T"
   },
   "outputs": [],
   "source": [
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oxAJSEZJcOi",
    "outputId": "9341fa23-14f6-46ec-b566-4d8d1b9451c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguous test accuracy: 0.9955855011940002\n",
      "Ground truth accuracy: 0.6186636090278625\n",
      "Unintended feature accuracy: 0.8744239807128906\n"
     ]
    }
   ],
   "source": [
    "probe, _ = train_probe(get_acts, label_idx=0)\n",
    "t.cuda.empty_cache()\n",
    "print('Ambiguous test accuracy:', test_probe(probe, get_acts, label_idx=0))\n",
    "batches = get_data(train=False, ambiguous=False)\n",
    "t.cuda.empty_cache()\n",
    "print('Ground truth accuracy:', test_probe(probe, get_acts, batches=batches, label_idx=0))\n",
    "t.cuda.empty_cache()\n",
    "print('Unintended feature accuracy:', test_probe(probe, get_acts, batches=batches, label_idx=1))\n",
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dogMY1E6Qyj4",
    "outputId": "29c7b0a7-a86f-4b1b-c42c-a60d59e3a774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probe saved successfully!\n"
     ]
    }
   ],
   "source": [
    "t.save(probe.state_dict(), 'tprobe4.pt') # Save only the model weights\n",
    "print(\"Probe saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51luHlTURiUX",
    "outputId": "ee912065-d074-4965-ab8f-46dfd1b06cbe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading probe from tprobe4.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_879/711491377.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  probe.load_state_dict(t.load('tprobe4.pt')) # Load the weights into the new model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Load the Probe\n",
    "print(f\"\\nLoading probe from {'tprobe4.pt'}...\")\n",
    "probe = Probe(512).to('cuda') # Create a new, empty probe model\n",
    "probe.load_state_dict(t.load('tprobe4.pt')) # Load the weights into the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHFDFQuEJcOi",
    "outputId": "150b6049-db83-43d7-cac0-16f6c7727aab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bilinear-feature-circuits/dictionary_learning/dictionary.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = t.load(path)\n"
     ]
    }
   ],
   "source": [
    "# loading dictionaries\n",
    "dict_id = 10\n",
    "\n",
    "embed = model.gpt_neox.embed_in\n",
    "attns = [l.attention for l in model.gpt_neox.layers[:layer+1]]\n",
    "mlps = [l.mlp for l in model.gpt_neox.layers[:layer+1]]\n",
    "resids = model.gpt_neox.layers[:layer+1]\n",
    "\n",
    "dictionaries = {}\n",
    "dictionaries[embed] = AutoEncoder.from_pretrained(\n",
    "    f'../dictionaries/pythia-70m-deduped/embed/{dict_id}_32768/ae.pt',\n",
    "    device=DEVICE\n",
    "\n",
    ")\n",
    "for i in range(layer + 1):\n",
    "    dictionaries[attns[i]] = AutoEncoder.from_pretrained(\n",
    "        f'../dictionaries/pythia-70m-deduped/attn_out_layer{i}/{dict_id}_32768/ae.pt',\n",
    "        device=DEVICE\n",
    "    )\n",
    "    dictionaries[mlps[i]] = AutoEncoder.from_pretrained(\n",
    "        f'../dictionaries/pythia-70m-deduped/mlp_out_layer{i}/{dict_id}_32768/ae.pt',\n",
    "        device=DEVICE\n",
    "    )\n",
    "    dictionaries[resids[i]] = AutoEncoder.from_pretrained(\n",
    "        f'../dictionaries/pythia-70m-deduped/resid_out_layer{i}/{dict_id}_32768/ae.pt',\n",
    "        device=DEVICE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XLQTQsnYJcOi"
   },
   "outputs": [],
   "source": [
    "# metric function for circuit discovery\n",
    "def metric_fn(model, labels=None):\n",
    "    attn_mask = model.inputs[1]['attention_mask']\n",
    "    acts = model.gpt_neox.layers[layer].output[0]\n",
    "    acts = acts * attn_mask[:, :, None]\n",
    "    acts = acts.sum(1) / attn_mask.sum(1)[:, None]\n",
    "\n",
    "    return t.where(\n",
    "        labels == 0,\n",
    "        probe(acts),\n",
    "        - probe(acts)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KvxMLX-AOqsX"
   },
   "outputs": [],
   "source": [
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "id": "PWXijTRgJcOi",
    "outputId": "bc875fe8-481c-4221-a0df-493684fcb1c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Integrated Gradient estimation\n",
      "\n",
      "\n",
      "Initial trace\n",
      "\n",
      "\n",
      "Patching part\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1212 19:48:24.940000 879 site-packages/torch/fx/experimental/symbolic_shapes.py:5124] failed during evaluate_expr(Eq(8*u0, 0), hint=None, size_oblivious=False, forcing_spec=False\n",
      "E1212 19:48:24.941000 879 site-packages/torch/fx/experimental/recording.py:298] failed while running evaluate_expr(*(Eq(8*u0, 0), None), **{'fx_node': False})\n",
      "  0%|          | 0/25 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "GuardOnDataDependentSymNode",
     "evalue": "Could not guard on data-dependent expression Eq(8*u0, 0) (unhinted: Eq(8*u0, 0)).  (Size-like symbols: u0)\n\nATTENTION: guard_size_oblivious would fix the error, evaluating expression to False.\nMaybe you need to add guard_size_oblivious to framework code, see doc below for more guidance.\n\nPotential framework code culprit (scroll up for full backtrace):\n  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n    return fn(*args, **kwargs)\n\nFor more information, run with TORCH_LOGS=\"dynamic\"\nFor extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"u0\"\nIf you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1\nFor more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing\n\nFor C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGuardOnDataDependentSymNode\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m==\u001b[39m n_batches:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m nodes, edges \u001b[38;5;241m=\u001b[39m \u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_circuit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdictionaries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# NOTE: use lower threshold if sigmoid\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m running_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(clean)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m running_nodes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/bilinear-feature-circuits/circuit.py:162\u001b[0m, in \u001b[0;36mget_circuit\u001b[0;34m(clean, patch, model, embed, attns, mlps, resids, dictionaries, metric_fn, metric_kwargs, aggregation, nodes_only, node_threshold, edge_threshold)\u001b[0m\n\u001b[1;32m    159\u001b[0m mlp \u001b[38;5;241m=\u001b[39m mlps[layer]\n\u001b[1;32m    160\u001b[0m attn \u001b[38;5;241m=\u001b[39m attns[layer]\n\u001b[0;32m--> 162\u001b[0m MR_effect, MR_grad \u001b[38;5;241m=\u001b[39m \u001b[43mN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m AR_effect, AR_grad \u001b[38;5;241m=\u001b[39m N(attn, resid)\n\u001b[1;32m    165\u001b[0m edges[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresid_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m MR_effect\n",
      "File \u001b[0;32m/bilinear-feature-circuits/circuit.py:143\u001b[0m, in \u001b[0;36mget_circuit.<locals>.N\u001b[0;34m(upstream, downstream)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mN\u001b[39m(upstream, downstream):\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjvp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdictionaries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_by_submod\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdownstream\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdownstream\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mupstream\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_without_right\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bilinear-feature-circuits/attribution.py:333\u001b[0m, in \u001b[0;36mjvp\u001b[0;34m(input, model, dictionaries, downstream_submod, downstream_features, upstream_submod, left_vec, right_vec, return_without_right)\u001b[0m\n\u001b[1;32m    330\u001b[0m     jv_indices \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    331\u001b[0m     jv_values \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 333\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracer_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# first specify forward pass modifications\u001b[39;49;00m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mupstream_submod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[43mupstream_submod\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/contexts/Tracer.py:102\u001b[0m, in \u001b[0;36mTracer.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoker\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_envoy\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/contexts/GraphBasedContext.py:215\u001b[0m, in \u001b[0;36mGraphBasedContext.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39malive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/bilinear-feature-circuits/attribution.py:365\u001b[0m, in \u001b[0;36mjvp\u001b[0;34m(input, model, dictionaries, downstream_submod, downstream_features, upstream_submod, left_vec, right_vec, return_without_right)\u001b[0m\n\u001b[1;32m    362\u001b[0m x_res\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mzeros_like(x_res)\n\u001b[1;32m    363\u001b[0m to_backprop[downstream_feat]\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 365\u001b[0m vjv_indices[downstream_feat] \u001b[38;5;241m=\u001b[39m \u001b[43mvjv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    366\u001b[0m vjv_values[downstream_feat] \u001b[38;5;241m=\u001b[39m vjv[vjv_indices[downstream_feat]]\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_without_right:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/intervention.py:156\u001b[0m, in \u001b[0;36mInterventionProxy.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     protocols\u001b[38;5;241m.\u001b[39mGradProtocol\u001b[38;5;241m.\u001b[39mincrement(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mgraph)\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    150\u001b[0m         proxy_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    151\u001b[0m         target\u001b[38;5;241m=\u001b[39mProxy\u001b[38;5;241m.\u001b[39mproxy_call,\n\u001b[1;32m    152\u001b[0m         args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    153\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    154\u001b[0m     )\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Proxy.py:76\u001b[0m, in \u001b[0;36mProxy.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Calling a Proxy object just creates a Proxy.proxy_call operation.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m        Proxy: New call proxy.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mProxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxy_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Node.py:270\u001b[0m, in \u001b[0;36mNode.create\u001b[0;34m(self, target, proxy_value, args, kwargs, name)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Otherwise just create the Node on the Graph like normal.\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxy_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxy_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Graph.py:113\u001b[0m, in \u001b[0;36mGraph.create\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Proxy:\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a Node directly on this `Graph` and returns its `Proxy`.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m        Proxy: `Proxy` for newly created `Node`.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy_class(\u001b[43mNode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Node.py:96\u001b[0m, in \u001b[0;36mNode.__init__\u001b[0;34m(self, target, graph, proxy_value, args, kwargs, name)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# If theres an alive Graph, add it.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattached():\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Graph.py:131\u001b[0m, in \u001b[0;36mGraph.add\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# If we're validating and the user did not provide a proxy_value, execute the given target with meta proxy values to compute new proxy_value.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39mproxy_value \u001b[38;5;129;01mis\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39m_empty:\n\u001b[0;32m--> 131\u001b[0m     node\u001b[38;5;241m.\u001b[39mproxy_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Get name of target.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    135\u001b[0m     node\u001b[38;5;241m.\u001b[39mtarget\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mtarget, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m node\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    138\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/util.py:20\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(target, *args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FakeTensorMode(\n\u001b[1;32m     15\u001b[0m     allow_non_fake_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m     shape_env\u001b[38;5;241m=\u001b[39mShapeEnv(assume_static_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     17\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m fake_mode:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m FakeCopyMode(fake_mode):\n\u001b[0;32m---> 20\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mGlobalTracingContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit_global_tracing_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/contexts/GraphBasedContext.py:350\u001b[0m, in \u001b[0;36mGlobalTracingContext.GlobalTracingExit.__exit__\u001b[0;34m(self, exc_type, exc_val, traceback)\u001b[0m\n\u001b[1;32m    346\u001b[0m GlobalTracingContext\u001b[38;5;241m.\u001b[39mPATCHER\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc_val, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/util.py:24\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(target, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m GlobalTracingContext\u001b[38;5;241m.\u001b[39mexit_global_tracing_context():\n\u001b[1;32m     22\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m Node\u001b[38;5;241m.\u001b[39mprepare_inputs((args, kwargs), proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Proxy.py:33\u001b[0m, in \u001b[0;36mProxy.proxy_call\u001b[0;34m(callable, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproxy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m: Callable, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/intervention.py:156\u001b[0m, in \u001b[0;36mInterventionProxy.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     protocols\u001b[38;5;241m.\u001b[39mGradProtocol\u001b[38;5;241m.\u001b[39mincrement(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mgraph)\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    150\u001b[0m         proxy_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    151\u001b[0m         target\u001b[38;5;241m=\u001b[39mProxy\u001b[38;5;241m.\u001b[39mproxy_call,\n\u001b[1;32m    152\u001b[0m         args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    153\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    154\u001b[0m     )\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Proxy.py:76\u001b[0m, in \u001b[0;36mProxy.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Calling a Proxy object just creates a Proxy.proxy_call operation.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m        Proxy: New call proxy.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mProxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxy_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Node.py:270\u001b[0m, in \u001b[0;36mNode.create\u001b[0;34m(self, target, proxy_value, args, kwargs, name)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Otherwise just create the Node on the Graph like normal.\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxy_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxy_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Graph.py:113\u001b[0m, in \u001b[0;36mGraph.create\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Proxy:\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a Node directly on this `Graph` and returns its `Proxy`.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m        Proxy: `Proxy` for newly created `Node`.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy_class(\u001b[43mNode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Node.py:96\u001b[0m, in \u001b[0;36mNode.__init__\u001b[0;34m(self, target, graph, proxy_value, args, kwargs, name)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# If theres an alive Graph, add it.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattached():\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Graph.py:131\u001b[0m, in \u001b[0;36mGraph.add\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# If we're validating and the user did not provide a proxy_value, execute the given target with meta proxy values to compute new proxy_value.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39mproxy_value \u001b[38;5;129;01mis\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39m_empty:\n\u001b[0;32m--> 131\u001b[0m     node\u001b[38;5;241m.\u001b[39mproxy_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Get name of target.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    135\u001b[0m     node\u001b[38;5;241m.\u001b[39mtarget\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mtarget, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m node\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    138\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/util.py:20\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(target, *args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FakeTensorMode(\n\u001b[1;32m     15\u001b[0m     allow_non_fake_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m     shape_env\u001b[38;5;241m=\u001b[39mShapeEnv(assume_static_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     17\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m fake_mode:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m FakeCopyMode(fake_mode):\n\u001b[0;32m---> 20\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mGlobalTracingContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit_global_tracing_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/contexts/GraphBasedContext.py:350\u001b[0m, in \u001b[0;36mGlobalTracingContext.GlobalTracingExit.__exit__\u001b[0;34m(self, exc_type, exc_val, traceback)\u001b[0m\n\u001b[1;32m    346\u001b[0m GlobalTracingContext\u001b[38;5;241m.\u001b[39mPATCHER\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc_val, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/util.py:24\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(target, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m GlobalTracingContext\u001b[38;5;241m.\u001b[39mexit_global_tracing_context():\n\u001b[1;32m     22\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m Node\u001b[38;5;241m.\u001b[39mprepare_inputs((args, kwargs), proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/tracing/Proxy.py:33\u001b[0m, in \u001b[0;36mProxy.proxy_call\u001b[0;34m(callable, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproxy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m: Callable, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nnsight/contexts/GraphBasedContext.py:332\u001b[0m, in \u001b[0;36mGlobalTracingContext.GlobalTracingTorchHandler.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_VariableFunctionsClass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GlobalTracingContext\u001b[38;5;241m.\u001b[39mGLOBAL_TRACING_CONTEXT\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    329\u001b[0m         func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/_stats.py:21\u001b[0m, in \u001b[0;36mcount.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m=\u001b[39m simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1238\u001b[0m, in \u001b[0;36mFakeTensorMode.__torch_dispatch__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   1235\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_dispatch_mode(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_TorchDispatchModeKey\u001b[38;5;241m.\u001b[39mFAKE) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m ), func\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1240\u001b[0m     log\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfake tensor raised TypeError\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1692\u001b[0m, in \u001b[0;36mFakeTensorMode.dispatch\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_enabled:\n\u001b[0;32m-> 1692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_dispatch_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_impl(func, types, args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1348\u001b[0m, in \u001b[0;36mFakeTensorMode._cached_dispatch_impl\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     FakeTensorMode\u001b[38;5;241m.\u001b[39mcache_bypasses[e\u001b[38;5;241m.\u001b[39mreason] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m _UNASSIGNED:\n\u001b[0;32m-> 1348\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1790\u001b[0m, in \u001b[0;36mFakeTensorMode._dispatch_impl\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         avoiding_device_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;66;03m# Recompute flat_arg_fake_tensors here again in case some of the inputs\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;66;03m# were real tensors and fakified in validate_and_convert_non_fake_tensors\u001b[39;00m\n\u001b[0;32m-> 1790\u001b[0m (flat_args, flat_arg_fake_tensors) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_and_convert_non_fake_tensors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m args, kwargs  \u001b[38;5;66;03m# Invalidated\u001b[39;00m\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;66;03m# The current constant handling only support tracing systems\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;66;03m# (aot autograd, torchdynamo) where each operation is run consecutively.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;66;03m# Because each operation is run in order, we can trace out and support\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1803\u001b[0m \n\u001b[1;32m   1804\u001b[0m \u001b[38;5;66;03m# We dispatch size/stride/numel on the FakeTensor not its constant, so bail on inplace_view\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:2094\u001b[0m, in \u001b[0;36mFakeTensorMode.validate_and_convert_non_fake_tensors\u001b[0;34m(self, func, converter, flat_args, args_spec)\u001b[0m\n\u001b[1;32m   2091\u001b[0m     flat_arg_fake_tensors\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[1;32m   2092\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m-> 2094\u001b[0m validated_args \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validated_args, flat_arg_fake_tensors\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:2094\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2091\u001b[0m     flat_arg_fake_tensors\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[1;32m   2092\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m-> 2094\u001b[0m validated_args \u001b[38;5;241m=\u001b[39m [\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m flat_args]\n\u001b[1;32m   2095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validated_args, flat_arg_fake_tensors\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:2087\u001b[0m, in \u001b[0;36mFakeTensorMode.validate_and_convert_non_fake_tensors.<locals>.validate\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2081\u001b[0m         args, kwargs \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_args, args_spec)\n\u001b[1;32m   2082\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m   2083\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease convert all Tensors to FakeTensors first or instantiate FakeTensorMode \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2084\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_non_fake_inputs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrender_call(func,\u001b[38;5;250m \u001b[39margs,\u001b[38;5;250m \u001b[39mkwargs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2085\u001b[0m         )\n\u001b[0;32m-> 2087\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_real_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2089\u001b[0m     out \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:375\u001b[0m, in \u001b[0;36mFakeTensorConverter.from_real_tensor\u001b[0;34m(self, fake_mode, t, make_constant, shape_env, source, symbolic_context, trace)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m no_dispatch():\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m FakeTensor(\n\u001b[1;32m    367\u001b[0m             fake_mode,\n\u001b[1;32m    368\u001b[0m             make_meta_t(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m             constant\u001b[38;5;241m=\u001b[39mt \u001b[38;5;28;01mif\u001b[39;00m make_constant \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    373\u001b[0m         )\n\u001b[0;32m--> 375\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta_converter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmk_fake_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43msymbolic_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbolic_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedFakeTensorException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta converter nyi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_subclasses/meta_utils.py:1660\u001b[0m, in \u001b[0;36mMetaConverter.__call__\u001b[0;34m(self, t, shape_env, callback, source, symbolic_context, trace)\u001b[0m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m st \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1656\u001b[0m         exit_stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   1657\u001b[0m             torch\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpyfunctorch\u001b[38;5;241m.\u001b[39mtemporarily_clear_interpreter_stack()\n\u001b[1;32m   1658\u001b[0m         )\n\u001b[0;32m-> 1660\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43msymbolic_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbolic_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t) \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter:\n\u001b[1;32m   1669\u001b[0m     \u001b[38;5;66;03m# NB: Cannot directly use Parameter constructor\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m     \u001b[38;5;66;03m# because that would force a detach, not desirable\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m     r\u001b[38;5;241m.\u001b[39m_is_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_subclasses/meta_utils.py:1572\u001b[0m, in \u001b[0;36mMetaConverter.meta_tensor\u001b[0;34m(self, t, shape_env, callback, source, symbolic_context)\u001b[0m\n\u001b[1;32m   1568\u001b[0m assert_metadata_eq(assert_eq, t, r, skip_symbolic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, skip_leaf\u001b[38;5;241m=\u001b[39mskip_leaf)\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;66;03m# Thanks to storage resizing, it's possible to end up with a tensor\u001b[39;00m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;66;03m# that advertises a real size, but has a storage that actually has zero bytes.\u001b[39;00m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;66;03m# Need to reflect this in the generated FakeTensor.\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mstorage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1573\u001b[0m     r\u001b[38;5;241m.\u001b[39muntyped_storage()\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_parameter:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/__init__.py:679\u001b[0m, in \u001b[0;36mSymBool.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py:511\u001b[0m, in \u001b[0;36mSymNode.bool_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbool_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguard_bool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py:449\u001b[0m, in \u001b[0;36mSymNode.guard_bool\u001b[0;34m(self, file, line)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mguard_bool\u001b[39m(\u001b[38;5;28mself\u001b[39m, file, line):\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;66;03m# TODO: use the file/line for some useful diagnostic on why a\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# guard occurred\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfx_node\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfx_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/fx/experimental/recording.py:262\u001b[0m, in \u001b[0;36mrecord_shapeenv_event.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mis_recording:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;66;03m# If ShapeEnv is already recording an event, call the wrapped\u001b[39;00m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;66;03m# function directly.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# NB: here, we skip the check of whether all ShapeEnv instances\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m# are equal, in favor of a faster dispatch.\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m retlog(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# Retrieve an instance of ShapeEnv.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# Assumption: the collection of args and kwargs may not reference\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# different ShapeEnv instances.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m _extract_shape_env_and_assert_equal(args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py:5122\u001b[0m, in \u001b[0;36mShapeEnv.evaluate_expr\u001b[0;34m(self, orig_expr, hint, fx_node, size_oblivious, forcing_spec)\u001b[0m\n\u001b[1;32m   5117\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(\u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m   5118\u001b[0m \u001b[38;5;129m@record_shapeenv_event\u001b[39m(save_tracked_fakes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_expr\u001b[39m(\u001b[38;5;28mself\u001b[39m, orig_expr: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msympy.Expr\u001b[39m\u001b[38;5;124m\"\u001b[39m, hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fx_node\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5120\u001b[0m                   size_oblivious: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, forcing_spec: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   5121\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5122\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_expr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfx_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_oblivious\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforcing_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforcing_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5123\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   5124\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   5125\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed during evaluate_expr(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, hint=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, size_oblivious=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, forcing_spec=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5126\u001b[0m             orig_expr, hint, size_oblivious, forcing_spec\n\u001b[1;32m   5127\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py:5238\u001b[0m, in \u001b[0;36mShapeEnv._evaluate_expr\u001b[0;34m(self, orig_expr, hint, fx_node, size_oblivious, forcing_spec)\u001b[0m\n\u001b[1;32m   5236\u001b[0m         concrete_val \u001b[38;5;241m=\u001b[39m unsound_result\n\u001b[1;32m   5237\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_data_dependent_error(\n\u001b[1;32m   5239\u001b[0m             expr\u001b[38;5;241m.\u001b[39mxreplace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_to_val),\n\u001b[1;32m   5240\u001b[0m             expr,\n\u001b[1;32m   5241\u001b[0m             size_oblivious_result\u001b[38;5;241m=\u001b[39msize_oblivious_result\n\u001b[1;32m   5242\u001b[0m         )\n\u001b[1;32m   5243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5244\u001b[0m     expr \u001b[38;5;241m=\u001b[39m new_expr\n",
      "\u001b[0;31mGuardOnDataDependentSymNode\u001b[0m: Could not guard on data-dependent expression Eq(8*u0, 0) (unhinted: Eq(8*u0, 0)).  (Size-like symbols: u0)\n\nATTENTION: guard_size_oblivious would fix the error, evaluating expression to False.\nMaybe you need to add guard_size_oblivious to framework code, see doc below for more guidance.\n\nPotential framework code culprit (scroll up for full backtrace):\n  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n    return fn(*args, **kwargs)\n\nFor more information, run with TORCH_LOGS=\"dynamic\"\nFor extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"u0\"\nIf you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1\nFor more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing\n\nFor C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1"
     ]
    }
   ],
   "source": [
    "# circuit discovery\n",
    "n_batches = 25\n",
    "batch_size = 4\n",
    "\n",
    "running_total = 0\n",
    "running_nodes = None\n",
    "running_edges = None\n",
    "for batch_idx, (clean, labels, _) in tqdm(enumerate(get_data(train=True, ambiguous=True, batch_size=batch_size, seed=SEED)), total=n_batches):\n",
    "    if batch_idx == n_batches:\n",
    "        break\n",
    "    nodes, edges = circuit.get_circuit(\n",
    "        clean,\n",
    "        None,\n",
    "        model,\n",
    "        embed,\n",
    "        attns,\n",
    "        mlps,\n",
    "        resids,\n",
    "        dictionaries,\n",
    "        metric_fn,\n",
    "        metric_kwargs={'labels': labels},\n",
    "        node_threshold=0.2, # NOTE: use lower threshold if sigmoid\n",
    "        edge_threshold=0.02,\n",
    "    )\n",
    "    running_total += len(clean)\n",
    "    if running_nodes is None:\n",
    "        running_nodes = { k : len(clean) * v.to('cpu') if k != 'y' else None for k, v in nodes.items() }\n",
    "        running_edges = { k : { kk : len(clean) * v.to('cpu') for kk, v in vv.items() } for k, vv in edges.items() }\n",
    "    else:\n",
    "        for k, effect in nodes.items():\n",
    "            if k == 'y': continue\n",
    "            running_nodes[k] += len(clean) * effect.to('cpu')\n",
    "        for k in edges.keys():\n",
    "            for kk, effect in edges[k].items():\n",
    "                running_edges[k][kk] += len(clean) * effect.to('cpu')\n",
    "    del nodes, edges\n",
    "    gc.collect()\n",
    "\n",
    "for k in running_nodes.keys():\n",
    "    if k == 'y': continue\n",
    "    running_nodes[k] = running_nodes[k].to('cuda:0') / running_total\n",
    "for k in running_edges.keys():\n",
    "    for kk in running_edges[k].keys():\n",
    "        running_edges[k][kk] = running_edges[k][kk].to('cuda:0') / running_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJ8dsmLDJcOj"
   },
   "outputs": [],
   "source": [
    "# only plot positive effect nodes\n",
    "running_nodes = {\n",
    "    k : SparseAct(act=t.clamp(v.act, min=0), resc=t.clamp(v.resc, min=0)) if v is not None else None for k, v in running_nodes.items()\n",
    "}\n",
    "\n",
    "# get annotations\n",
    "try:\n",
    "    annotations = {}\n",
    "    with open(f\"../annotations/10_32768.jsonl\", 'r') as annotations_data:\n",
    "        for annotation_line in annotations_data:\n",
    "            annotation = json.loads(annotation_line)\n",
    "            annotations[annotation[\"Name\"]] = annotation[\"Annotation\"]\n",
    "except:\n",
    "    annotations = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhdLYf6ZJcOj"
   },
   "outputs": [],
   "source": [
    "plot_circuit(\n",
    "    running_nodes,\n",
    "    running_edges,\n",
    "    layers=5,\n",
    "    node_threshold=0.1,\n",
    "    edge_threshold=0.01,\n",
    "    pen_thickness=1,\n",
    "    save_dir='../circuits/figures/bib_circuit',\n",
    "    annotations=annotations\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
