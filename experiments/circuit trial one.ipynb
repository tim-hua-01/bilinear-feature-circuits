{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/saprmarks/feature-circuits.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9n04rxDFtOm",
        "outputId": "428ddb1a-88aa-41d1-857b-7e0ae48075f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'feature-circuits'...\n",
            "remote: Enumerating objects: 1674, done.\u001b[K\n",
            "remote: Counting objects: 100% (578/578), done.\u001b[K\n",
            "remote: Compressing objects: 100% (315/315), done.\u001b[K\n",
            "remote: Total 1674 (delta 284), reused 263 (delta 263), pack-reused 1096 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1674/1674), 32.93 MiB | 5.88 MiB/s, done.\n",
            "Resolving deltas: 100% (1059/1059), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "collapsed": true,
        "id": "OJ16XnQyGVsz",
        "outputId": "08d3d36e-af25-48f8-fe95-d718b90d23df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
            "  Cloning https://github.com/callummcdougall/CircuitsVis.git to /tmp/pip-req-build-gkvp2k1r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/callummcdougall/CircuitsVis.git /tmp/pip-req-build-gkvp2k1r\n",
            "  Resolved https://github.com/callummcdougall/CircuitsVis.git to commit 1e6129d08cae7af9242d9ab5d3ed322dd44b4dd3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata<6.0.0,>=5.1.0 (from circuitsvis==0.0.0)\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis==0.0.0) (3.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0,>=2.0->circuitsvis==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0,>=2.0->circuitsvis==0.0.0) (3.0.2)\n",
            "Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Building wheels for collected packages: circuitsvis\n",
            "  Building wheel for circuitsvis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for circuitsvis: filename=circuitsvis-0.0.0-py3-none-any.whl size=6172338 sha256=68db3afdea2d0e0a3142f410b568f7fb47ad97e53e63d3bda9d115fcb49e76ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s9257rgx/wheels/86/be/ad/78078aba9344d200aad61b63d35cdaecdec160212f039eed74\n",
            "Successfully built circuitsvis\n",
            "Installing collected packages: importlib-metadata, circuitsvis\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.5.0\n",
            "    Uninstalling importlib_metadata-8.5.0:\n",
            "      Successfully uninstalled importlib_metadata-8.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-api 1.28.2 requires importlib-metadata<=8.5.0,>=6.0, but you have importlib-metadata 5.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed circuitsvis-0.0.0 importlib-metadata-5.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "5fc5f4d1b8c145deabc44ef952f71d30"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets>=2.18.0\n",
        "!pip install einops>=0.7.0\n",
        "!pip install graphviz>=0.20.1\n",
        "!pip install nnsight>=0.2.9\n",
        "!pip install torchtyping\n",
        "!pip install jaxtyping\n",
        "!pip install transformer_lens\n",
        "!pip install umap\n",
        "!pip install zstandard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkFShEAQF0th",
        "outputId": "78546ddd-05fd-4362-efcd-2129e609468b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting torchtyping\n",
            "  Downloading torchtyping-0.1.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtyping) (2.5.1+cu121)\n",
            "Collecting typeguard<3,>=2.11.1 (from torchtyping)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.0->torchtyping) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->torchtyping) (3.0.2)\n",
            "Downloading torchtyping-0.1.5-py3-none-any.whl (17 kB)\n",
            "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, torchtyping\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torchtyping-0.1.5 typeguard-2.13.3\n",
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.2.36-py3-none-any.whl.metadata (6.5 kB)\n",
            "Downloading jaxtyping-0.2.36-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jaxtyping\n",
            "Successfully installed jaxtyping-0.2.36\n",
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-2.9.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.1.1)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (3.2.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.8.0)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.2.36)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.6)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.46.3)\n",
            "Collecting typeguard<5.0,>=4.2 (from transformer_lens)\n",
            "  Downloading typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.12.2)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.18.7)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.11.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (0.20.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (4.25.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (2.19.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n",
            "Downloading transformer_lens-2.9.1-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: better-abc, typeguard, fancy-einsum, beartype, transformer_lens\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 2.13.3\n",
            "    Uninstalling typeguard-2.13.3:\n",
            "      Successfully uninstalled typeguard-2.13.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtyping 0.1.5 requires typeguard<3,>=2.11.1, but you have typeguard 4.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 fancy-einsum-0.0.3 transformer_lens-2.9.1 typeguard-4.4.1\n",
            "Collecting umap\n",
            "  Downloading umap-0.1.1.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: umap\n",
            "  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3542 sha256=c2fd00b1d8115530f48fdeb746baa9cb7ca4a6858b9138e8ff0600ac738bc2bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/f1/28/53dcf7a309118ed35d810a5f9cb995217800f3f269ab5771cb\n",
            "Successfully built umap\n",
            "Installing collected packages: umap\n",
            "Successfully installed umap-0.1.1\n",
            "Collecting zstandard\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zstandard\n",
            "Successfully installed zstandard-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd feature-circuits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74UEeEnjHS0F",
        "outputId": "1ed2fe64-fede-443a-ee1a-272d57fa68fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/feature-circuits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule update --init"
      ],
      "metadata": {
        "id": "_PopGrtyHNP1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd experiments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLdJhB3CF_g6",
        "outputId": "0a1bb48c-e251-4f2f-fa67-eb48f7d1ac5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/feature-circuits/experiments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "rqhyDYVxUeWz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ROVZw-cGJcOh"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "parent_dir = os.path.abspath('..')\n",
        "sys.path.append(parent_dir)\n",
        "\n",
        "from nnsight import LanguageModel\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "from dictionary_learning import AutoEncoder\n",
        "import circuit\n",
        "from circuit import get_circuit\n",
        "from circuit_plotting import plot_circuit\n",
        "from activation_utils import SparseAct\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import gc\n",
        "\n",
        "DEBUGGING = True\n",
        "if DEBUGGING:\n",
        "    tracer_kwargs = {'validate' : True, 'scan' : True}\n",
        "else:\n",
        "    tracer_kwargs = {'validate' : False, 'scan' : False}\n",
        "\n",
        "DEVICE = 'cuda:0'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map=DEVICE, dispatch=True)"
      ],
      "metadata": {
        "id": "MI3aUIc9QYUC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zaHOwq_RJcOh"
      },
      "outputs": [],
      "source": [
        "# utilities for loading data\n",
        "dataset = load_dataset(\"LabHC/bias_in_bios\")\n",
        "profession_dict = {'professor' : 21, 'nurse' : 13}\n",
        "male_prof = 'professor'\n",
        "female_prof = 'nurse'\n",
        "\n",
        "batch_size = 1024\n",
        "SEED = 42\n",
        "\n",
        "def get_data(train=True, ambiguous=True, batch_size=128, seed=SEED):\n",
        "    if train:\n",
        "        data = dataset['train']\n",
        "    else:\n",
        "        data = dataset['test']\n",
        "    if ambiguous:\n",
        "        neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 0]\n",
        "        pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 1]\n",
        "        n = min([len(neg), len(pos)])\n",
        "        neg, pos = neg[:n], pos[:n]\n",
        "        data = neg + pos\n",
        "        labels = [0]*n + [1]*n\n",
        "        idxs = list(range(2*n))\n",
        "        random.Random(seed).shuffle(idxs)\n",
        "        data, labels = [data[i] for i in idxs], [labels[i] for i in idxs]\n",
        "        true_labels = spurious_labels = labels\n",
        "    else:\n",
        "        neg_neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 0]\n",
        "        neg_pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 1]\n",
        "        pos_neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 0]\n",
        "        pos_pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 1]\n",
        "        n = min([len(neg_neg), len(neg_pos), len(pos_neg), len(pos_pos)])\n",
        "        neg_neg, neg_pos, pos_neg, pos_pos = neg_neg[:n], neg_pos[:n], pos_neg[:n], pos_pos[:n]\n",
        "        data = neg_neg + neg_pos + pos_neg + pos_pos\n",
        "        true_labels     = [0]*n + [0]*n + [1]*n + [1]*n\n",
        "        spurious_labels = [0]*n + [1]*n + [0]*n + [1]*n\n",
        "        idxs = list(range(4*n))\n",
        "        random.Random(seed).shuffle(idxs)\n",
        "        data, true_labels, spurious_labels = [data[i] for i in idxs], [true_labels[i] for i in idxs], [spurious_labels[i] for i in idxs]\n",
        "\n",
        "    batches = [\n",
        "        (data[i:i+batch_size], t.tensor(true_labels[i:i+batch_size], device=DEVICE), t.tensor(spurious_labels[i:i+batch_size], device=DEVICE)) for i in range(0, len(data), batch_size)\n",
        "    ]\n",
        "\n",
        "    return batches\n",
        "\n",
        "def get_subgroups(train=True, ambiguous=True, batch_size=128, seed=SEED):\n",
        "    if train:\n",
        "        data = dataset['train']\n",
        "    else:\n",
        "        data = dataset['test']\n",
        "    if ambiguous:\n",
        "        neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 0]\n",
        "        pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 1]\n",
        "        neg_labels, pos_labels = (0, 0), (1, 1)\n",
        "        subgroups = [(neg, neg_labels), (pos, pos_labels)]\n",
        "    else:\n",
        "        neg_neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 0]\n",
        "        neg_pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[male_prof] and x['gender'] == 1]\n",
        "        pos_neg = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 0]\n",
        "        pos_pos = [x['hard_text'] for x in data if x['profession'] == profession_dict[female_prof] and x['gender'] == 1]\n",
        "        neg_neg_labels, neg_pos_labels, pos_neg_labels, pos_pos_labels = (0, 0), (0, 1), (1, 0), (1, 1)\n",
        "        subgroups = [(neg_neg, neg_neg_labels), (neg_pos, neg_pos_labels), (pos_neg, pos_neg_labels), (pos_pos, pos_pos_labels)]\n",
        "\n",
        "    out = {}\n",
        "    for data, label_profile in subgroups:\n",
        "        out[label_profile] = []\n",
        "        for i in range(0, len(data), batch_size):\n",
        "            text = data[i:i+batch_size]\n",
        "            out[label_profile].append(\n",
        "                (\n",
        "                    text,\n",
        "                    t.tensor([label_profile[0]]*len(text), device=DEVICE),\n",
        "                    t.tensor([label_profile[1]]*len(text), device=DEVICE)\n",
        "                )\n",
        "            )\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B91RTKHRJcOi"
      },
      "outputs": [],
      "source": [
        "# probe training hyperparameters\n",
        "\n",
        "layer = 4 # the model layer to attach linear classification head to\n",
        "\n",
        "class Probe(nn.Module):\n",
        "    def __init__(self, activation_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(activation_dim, 1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.net(x).squeeze(-1)\n",
        "        return logits\n",
        "\n",
        "def train_probe(get_acts, label_idx=0, batches=get_data(), lr=1e-2, epochs=1, dim=512, seed=SEED):\n",
        "    t.manual_seed(seed)\n",
        "    probe = Probe(dim).to('cuda:0')\n",
        "    optimizer = t.optim.AdamW(probe.parameters(), lr=lr)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        for batch in batches:\n",
        "            text = batch[0]\n",
        "            labels = batch[label_idx+1]\n",
        "            acts = get_acts(text)\n",
        "            logits = probe(acts)\n",
        "            loss = criterion(logits, labels.float())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return probe, losses\n",
        "\n",
        "def test_probe(probe, get_acts, label_idx=0, batches=get_data(train=False), seed=SEED):\n",
        "    with t.no_grad():\n",
        "        corrects = []\n",
        "\n",
        "        for batch in batches:\n",
        "            text = batch[0]\n",
        "            labels = batch[label_idx+1]\n",
        "            acts = get_acts(text)\n",
        "            logits = probe(acts)\n",
        "            preds = (logits > 0.0).long()\n",
        "            corrects.append((preds == labels).float())\n",
        "        return t.cat(corrects).mean().item()\n",
        "\n",
        "def get_acts(text):\n",
        "    with t.no_grad():\n",
        "        with model.trace(text, **tracer_kwargs):\n",
        "            attn_mask = model.inputs[1]['attention_mask']\n",
        "            acts = model.gpt_neox.layers[layer].output[0]\n",
        "            acts = acts * attn_mask[:, :, None]\n",
        "            acts = acts.sum(1) / attn_mask.sum(1)[:, None]\n",
        "            acts = acts.save()\n",
        "        return acts.value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1+1"
      ],
      "metadata": {
        "id": "mevUIDmeVK2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "EdX5APPeR_9T"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oxAJSEZJcOi",
        "outputId": "9341fa23-14f6-46ec-b566-4d8d1b9451c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ambiguous test accuracy: 0.9955855011940002\n",
            "Ground truth accuracy: 0.6186636090278625\n",
            "Unintended feature accuracy: 0.8744239807128906\n"
          ]
        }
      ],
      "source": [
        "probe, _ = train_probe(get_acts, label_idx=0)\n",
        "t.cuda.empty_cache()\n",
        "print('Ambiguous test accuracy:', test_probe(probe, get_acts, label_idx=0))\n",
        "batches = get_data(train=False, ambiguous=False)\n",
        "t.cuda.empty_cache()\n",
        "print('Ground truth accuracy:', test_probe(probe, get_acts, batches=batches, label_idx=0))\n",
        "t.cuda.empty_cache()\n",
        "print('Unintended feature accuracy:', test_probe(probe, get_acts, batches=batches, label_idx=1))\n",
        "t.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.save(probe.state_dict(), 'tprobe4.pt') # Save only the model weights\n",
        "print(\"Probe saved successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dogMY1E6Qyj4",
        "outputId": "29c7b0a7-a86f-4b1b-c42c-a60d59e3a774"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probe saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Load the Probe\n",
        "print(f\"\\nLoading probe from {'tprobe.pt'}...\")\n",
        "probe = Probe(512).to('cuda') # Create a new, empty probe model\n",
        "probe.load_state_dict(t.load('tprobe.pt')) # Load the weights into the new model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51luHlTURiUX",
        "outputId": "ee912065-d074-4965-ab8f-46dfd1b06cbe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading probe from tprobe.pt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1e8c3ad363aa>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  probe.load_state_dict(t.load('tprobe.pt')) # Load the weights into the new model\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHFDFQuEJcOi",
        "outputId": "150b6049-db83-43d7-cac0-16f6c7727aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/feature-circuits/dictionary_learning/dictionary.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = t.load(path)\n"
          ]
        }
      ],
      "source": [
        "# loading dictionaries\n",
        "dict_id = 10\n",
        "\n",
        "embed = model.gpt_neox.embed_in\n",
        "attns = [l.attention for l in model.gpt_neox.layers[:layer+1]]\n",
        "mlps = [l.mlp for l in model.gpt_neox.layers[:layer+1]]\n",
        "resids = model.gpt_neox.layers[:layer+1]\n",
        "\n",
        "dictionaries = {}\n",
        "dictionaries[embed] = AutoEncoder.from_pretrained(\n",
        "    f'../dictionaries/pythia-70m-deduped/embed/{dict_id}_32768/ae.pt',\n",
        "    device=DEVICE\n",
        "\n",
        ")\n",
        "for i in range(layer + 1):\n",
        "    dictionaries[attns[i]] = AutoEncoder.from_pretrained(\n",
        "        f'../dictionaries/pythia-70m-deduped/attn_out_layer{i}/{dict_id}_32768/ae.pt',\n",
        "        device=DEVICE\n",
        "    )\n",
        "    dictionaries[mlps[i]] = AutoEncoder.from_pretrained(\n",
        "        f'../dictionaries/pythia-70m-deduped/mlp_out_layer{i}/{dict_id}_32768/ae.pt',\n",
        "        device=DEVICE\n",
        "    )\n",
        "    dictionaries[resids[i]] = AutoEncoder.from_pretrained(\n",
        "        f'../dictionaries/pythia-70m-deduped/resid_out_layer{i}/{dict_id}_32768/ae.pt',\n",
        "        device=DEVICE\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/saprmarks/pythia-70m-deduped-saes/resolve/main/dictionaries_pythia-70m-deduped_10.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TQgXyBMANFwM",
        "outputId": "6d7dda83-3d78-457f-9d14-c7a4bd11479a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-12 00:11:04--  https://huggingface.co/saprmarks/pythia-70m-deduped-saes/resolve/main/dictionaries_pythia-70m-deduped_10.zip\n",
            "Resolving huggingface.co (huggingface.co)... 3.171.171.104, 3.171.171.65, 3.171.171.128, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.171.171.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/0a/95/0a9507148e8bb09a3e4e35d968bfa7cf4eae1c325d49ffca3d70df152b440419/e8e320f0d068b2edf6b43ae2b641c96aaf0b3e5631cf173576325d4ad75c7979?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27dictionaries_pythia-70m-deduped_10.zip%3B+filename%3D%22dictionaries_pythia-70m-deduped_10.zip%22%3B&response-content-type=application%2Fzip&Expires=1734221464&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDIyMTQ2NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzBhLzk1LzBhOTUwNzE0OGU4YmIwOWEzZTRlMzVkOTY4YmZhN2NmNGVhZTFjMzI1ZDQ5ZmZjYTNkNzBkZjE1MmI0NDA0MTkvZThlMzIwZjBkMDY4YjJlZGY2YjQzYWUyYjY0MWM5NmFhZjBiM2U1NjMxY2YxNzM1NzYzMjVkNGFkNzVjNzk3OT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=UOMneRi66m6Fw1x9TFzfbEtWoiacLTqmqjwb3Gg9UThPuZLp4wIbyIosHHpDL8rS1wRHWFYS9ia8stufOK5tc6H1o5%7EwArGGdZGrBJaMexQSki0vjbRbu-dD2EzIeG-27G-eaPtsOFm2Fd5Cikxy7UqjP1P%7E9gBOuLtJ28OPXwgDaEyJrDtCobjMvVz4sHn4imB4ZouYtbRa9DqwyAGtZEjz6Hh7ZxD5W8shF9CPPRpmkOL5hWwzTWXJ8qzzbHeVY0PRNw%7EeJ5G-C0Ria4uNciNJX4vv6946vGlloXdMPkTPf9cP%7EoOMFqTr4IYmbQeUfRU7QrWedYiBdO66AkQ6lQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2024-12-12 00:11:04--  https://cdn-lfs-us-1.hf.co/repos/0a/95/0a9507148e8bb09a3e4e35d968bfa7cf4eae1c325d49ffca3d70df152b440419/e8e320f0d068b2edf6b43ae2b641c96aaf0b3e5631cf173576325d4ad75c7979?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27dictionaries_pythia-70m-deduped_10.zip%3B+filename%3D%22dictionaries_pythia-70m-deduped_10.zip%22%3B&response-content-type=application%2Fzip&Expires=1734221464&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDIyMTQ2NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzBhLzk1LzBhOTUwNzE0OGU4YmIwOWEzZTRlMzVkOTY4YmZhN2NmNGVhZTFjMzI1ZDQ5ZmZjYTNkNzBkZjE1MmI0NDA0MTkvZThlMzIwZjBkMDY4YjJlZGY2YjQzYWUyYjY0MWM5NmFhZjBiM2U1NjMxY2YxNzM1NzYzMjVkNGFkNzVjNzk3OT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=UOMneRi66m6Fw1x9TFzfbEtWoiacLTqmqjwb3Gg9UThPuZLp4wIbyIosHHpDL8rS1wRHWFYS9ia8stufOK5tc6H1o5%7EwArGGdZGrBJaMexQSki0vjbRbu-dD2EzIeG-27G-eaPtsOFm2Fd5Cikxy7UqjP1P%7E9gBOuLtJ28OPXwgDaEyJrDtCobjMvVz4sHn4imB4ZouYtbRa9DqwyAGtZEjz6Hh7ZxD5W8shF9CPPRpmkOL5hWwzTWXJ8qzzbHeVY0PRNw%7EeJ5G-C0Ria4uNciNJX4vv6946vGlloXdMPkTPf9cP%7EoOMFqTr4IYmbQeUfRU7QrWedYiBdO66AkQ6lQ__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.164.78.17, 18.164.78.6, 18.164.78.101, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.164.78.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2369891306 (2.2G) [application/zip]\n",
            "Saving to: ‘dictionaries_pythia-70m-deduped_10.zip’\n",
            "\n",
            "dictionaries_pythia 100%[===================>]   2.21G  40.0MB/s    in 56s     \n",
            "\n",
            "2024-12-12 00:12:01 (40.1 MB/s) - ‘dictionaries_pythia-70m-deduped_10.zip’ saved [2369891306/2369891306]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dictionaries_pythia-70m-deduped_10.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yuSFv-AMNbiZ",
        "outputId": "4dee903a-a56d-4b40-91ff-a4913d901203"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dictionaries_pythia-70m-deduped_10.zip\n",
            "   creating: dictionaries/\n",
            "   creating: dictionaries/pythia-70m-deduped/\n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer0/\n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer0/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer0/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer0/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer0/\n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer0/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer0/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer0/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer0/\n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer0/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer0/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer0/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer1/\n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer1/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer1/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer1/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer1/\n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer1/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer1/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer1/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer1/\n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer1/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer1/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer1/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer2/\n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer2/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer2/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer2/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer2/\n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer2/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer2/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer2/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer2/\n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer2/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer2/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer2/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer3/\n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer3/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer3/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer3/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer3/\n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer3/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer3/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer3/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer3/\n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer3/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer3/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer3/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer4/\n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer4/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer4/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer4/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer4/\n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer4/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer4/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer4/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer4/\n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer4/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer4/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer4/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer5/\n",
            "   creating: dictionaries/pythia-70m-deduped/attn_out_layer5/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer5/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/attn_out_layer5/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer5/\n",
            "   creating: dictionaries/pythia-70m-deduped/mlp_out_layer5/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer5/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/mlp_out_layer5/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer5/\n",
            "   creating: dictionaries/pythia-70m-deduped/resid_out_layer5/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer5/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/resid_out_layer5/10_32768/config.json  \n",
            "   creating: dictionaries/pythia-70m-deduped/embed/\n",
            "   creating: dictionaries/pythia-70m-deduped/embed/10_32768/\n",
            "  inflating: dictionaries/pythia-70m-deduped/embed/10_32768/ae.pt  \n",
            "  inflating: dictionaries/pythia-70m-deduped/embed/10_32768/config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XLQTQsnYJcOi"
      },
      "outputs": [],
      "source": [
        "# metric function for circuit discovery\n",
        "def metric_fn(model, labels=None):\n",
        "    attn_mask = model.inputs[1]['attention_mask']\n",
        "    acts = model.gpt_neox.layers[layer].output[0]\n",
        "    acts = acts * attn_mask[:, :, None]\n",
        "    acts = acts.sum(1) / attn_mask.sum(1)[:, None]\n",
        "\n",
        "    return t.where(\n",
        "        labels == 0,\n",
        "        probe(acts),\n",
        "        - probe(acts)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "KvxMLX-AOqsX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "PWXijTRgJcOi",
        "outputId": "bc875fe8-481c-4221-a0df-493684fcb1c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Integrated gradient!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:48<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1.06 GiB. GPU 0 has a total capacity of 14.75 GiB of which 315.06 MiB is free. Process 181509 has 14.44 GiB memory in use. Of the allocated memory 12.64 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-64fe0f825421>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     nodes, edges = circuit.get_circuit(\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/feature-circuits/circuit.py\u001b[0m in \u001b[0;36mget_circuit\u001b[0;34m(clean, patch, model, embed, attns, mlps, resids, dictionaries, metric_fn, metric_kwargs, aggregation, nodes_only, node_threshold, edge_threshold)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# first get the patching effect of everything on y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     effects, deltas, grads, total_effect = patching_effect(\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/feature-circuits/attribution.py\u001b[0m in \u001b[0;36mpatching_effect\u001b[0;34m(clean, patch, model, submodules, dictionaries, metric_fn, method, steps, metric_kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pe_attrib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ig'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pe_ig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exact'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pe_exact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/feature-circuits/attribution.py\u001b[0m in \u001b[0;36m_pe_ig\u001b[0;34m(clean, patch, model, submodules, dictionaries, metric_fn, steps, metric_kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mclean_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mpatch_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states_patch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtracer_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/contexts/Tracer.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mInvoker\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/contexts/GraphBasedContext.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;31m### BACKENDS ########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/contexts/backends/LocalBackend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLocalMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_backend_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/contexts/Tracer.py\u001b[0m in \u001b[0;36mlocal_backend_execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         self.model.interleave(\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/models/NNsightModel.py\u001b[0m in \u001b[0;36minterleave\u001b[0;34m(self, fn, intervention_graph, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mmodule_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInterventionProtocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interventions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintervention_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         with HookHandler(\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/intervention.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/models/NNsightModel.py\u001b[0m in \u001b[0;36minterleave\u001b[0;34m(self, fn, intervention_graph, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m         ):\n\u001b[1;32m    479\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                 \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mprotocols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopProtocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0;31m# TODO: Log.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/models/mixins/Generation.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, generate, *args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     def _scan(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/models/LanguageModel.py\u001b[0m in \u001b[0;36m_execute_forward\u001b[0;34m(self, prepared_inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         return self._model(\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mprepared_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m             \u001b[0;31m# run always called hooks if they have not already been run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1788\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m                 for hook_id, hook in (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, inputs_embeds, head_mask, past_key_values, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mlm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m             \u001b[0;31m# run always called hooks if they have not already been run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1788\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m                 for hook_id, hook in (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.06 GiB. GPU 0 has a total capacity of 14.75 GiB of which 315.06 MiB is free. Process 181509 has 14.44 GiB memory in use. Of the allocated memory 12.64 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# circuit discovery\n",
        "n_batches = 25\n",
        "batch_size = 4\n",
        "\n",
        "running_total = 0\n",
        "running_nodes = None\n",
        "running_edges = None\n",
        "for batch_idx, (clean, labels, _) in tqdm(enumerate(get_data(train=True, ambiguous=True, batch_size=batch_size, seed=SEED)), total=n_batches):\n",
        "    if batch_idx == n_batches:\n",
        "        break\n",
        "    nodes, edges = circuit.get_circuit(\n",
        "        clean,\n",
        "        None,\n",
        "        model,\n",
        "        embed,\n",
        "        attns,\n",
        "        mlps,\n",
        "        resids,\n",
        "        dictionaries,\n",
        "        metric_fn,\n",
        "        metric_kwargs={'labels': labels},\n",
        "        node_threshold=0.2, # NOTE: use lower threshold if sigmoid\n",
        "        edge_threshold=0.02,\n",
        "    )\n",
        "    running_total += len(clean)\n",
        "    if running_nodes is None:\n",
        "        running_nodes = { k : len(clean) * v.to('cpu') if k != 'y' else None for k, v in nodes.items() }\n",
        "        running_edges = { k : { kk : len(clean) * v.to('cpu') for kk, v in vv.items() } for k, vv in edges.items() }\n",
        "    else:\n",
        "        for k, effect in nodes.items():\n",
        "            if k == 'y': continue\n",
        "            running_nodes[k] += len(clean) * effect.to('cpu')\n",
        "        for k in edges.keys():\n",
        "            for kk, effect in edges[k].items():\n",
        "                running_edges[k][kk] += len(clean) * effect.to('cpu')\n",
        "    del nodes, edges\n",
        "    gc.collect()\n",
        "\n",
        "for k in running_nodes.keys():\n",
        "    if k == 'y': continue\n",
        "    running_nodes[k] = running_nodes[k].to('cuda:0') / running_total\n",
        "for k in running_edges.keys():\n",
        "    for kk in running_edges[k].keys():\n",
        "        running_edges[k][kk] = running_edges[k][kk].to('cuda:0') / running_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ8dsmLDJcOj"
      },
      "outputs": [],
      "source": [
        "# only plot positive effect nodes\n",
        "running_nodes = {\n",
        "    k : SparseAct(act=t.clamp(v.act, min=0), resc=t.clamp(v.resc, min=0)) if v is not None else None for k, v in running_nodes.items()\n",
        "}\n",
        "\n",
        "# get annotations\n",
        "try:\n",
        "    annotations = {}\n",
        "    with open(f\"../annotations/10_32768.jsonl\", 'r') as annotations_data:\n",
        "        for annotation_line in annotations_data:\n",
        "            annotation = json.loads(annotation_line)\n",
        "            annotations[annotation[\"Name\"]] = annotation[\"Annotation\"]\n",
        "except:\n",
        "    annotations = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhdLYf6ZJcOj"
      },
      "outputs": [],
      "source": [
        "plot_circuit(\n",
        "    running_nodes,\n",
        "    running_edges,\n",
        "    layers=5,\n",
        "    node_threshold=0.1,\n",
        "    edge_threshold=0.01,\n",
        "    pen_thickness=1,\n",
        "    save_dir='../circuits/figures/bib_circuit',\n",
        "    annotations=annotations\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}